{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/yangxiaojun/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"./1400-0.txt\"\n",
    "\n",
    "raw_text = open(filename, encoding='utf-8').read()\n",
    "\n",
    "raw_text = raw_text.lower() \n",
    "\n",
    "raw_text = raw_text.replace('\\ufeff', '')\n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'ê',\n",
       " 'ô',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars\n",
    "# len(chars)\n",
    "# len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(raw_text) - seq_length):\n",
    "    given = raw_text[i:i+seq_length]\n",
    "    predict = raw_text[i + seq_length]\n",
    "    x.append([char_to_int[char] for char in given])\n",
    "    y.append(char_to_int[predict])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49, 37, 34, 1, 45, 47, 44, 39, 34, 32, 49, 1, 36, 50, 49, 34, 43, 31, 34, 47, 36, 1, 34, 31, 44, 44, 40, 1, 44, 35, 1, 36, 47, 34, 30, 49, 1, 34, 53, 45, 34, 32, 49, 30, 49, 38, 44, 43, 48, 10, 1, 31, 54, 1, 32, 37, 30, 47, 41, 34, 48, 1, 33, 38, 32, 40, 34, 43, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44, 35, 1], [37, 34, 1, 45, 47, 44, 39, 34, 32, 49, 1, 36, 50, 49, 34, 43, 31, 34, 47, 36, 1, 34, 31, 44, 44, 40, 1, 44, 35, 1, 36, 47, 34, 30, 49, 1, 34, 53, 45, 34, 32, 49, 30, 49, 38, 44, 43, 48, 10, 1, 31, 54, 1, 32, 37, 30, 47, 41, 34, 48, 1, 33, 38, 32, 40, 34, 43, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44, 35, 1, 30], [34, 1, 45, 47, 44, 39, 34, 32, 49, 1, 36, 50, 49, 34, 43, 31, 34, 47, 36, 1, 34, 31, 44, 44, 40, 1, 44, 35, 1, 36, 47, 34, 30, 49, 1, 34, 53, 45, 34, 32, 49, 30, 49, 38, 44, 43, 48, 10, 1, 31, 54, 1, 32, 37, 30, 47, 41, 34, 48, 1, 33, 38, 32, 40, 34, 43, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44, 35, 1, 30, 43]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5483871 ]\n",
      " [ 0.01612903]\n",
      " [ 0.72580645]\n",
      " [ 0.75806452]\n",
      " [ 0.70967742]\n",
      " [ 0.62903226]\n",
      " [ 0.5483871 ]\n",
      " [ 0.51612903]\n",
      " [ 0.79032258]\n",
      " [ 0.01612903]\n",
      " [ 0.58064516]\n",
      " [ 0.80645161]\n",
      " [ 0.79032258]\n",
      " [ 0.5483871 ]\n",
      " [ 0.69354839]\n",
      " [ 0.5       ]\n",
      " [ 0.5483871 ]\n",
      " [ 0.75806452]\n",
      " [ 0.58064516]\n",
      " [ 0.01612903]\n",
      " [ 0.5483871 ]\n",
      " [ 0.5       ]\n",
      " [ 0.70967742]\n",
      " [ 0.70967742]\n",
      " [ 0.64516129]\n",
      " [ 0.01612903]\n",
      " [ 0.70967742]\n",
      " [ 0.56451613]\n",
      " [ 0.01612903]\n",
      " [ 0.58064516]\n",
      " [ 0.75806452]\n",
      " [ 0.5483871 ]\n",
      " [ 0.48387097]\n",
      " [ 0.79032258]\n",
      " [ 0.01612903]\n",
      " [ 0.5483871 ]\n",
      " [ 0.85483871]\n",
      " [ 0.72580645]\n",
      " [ 0.5483871 ]\n",
      " [ 0.51612903]\n",
      " [ 0.79032258]\n",
      " [ 0.48387097]\n",
      " [ 0.79032258]\n",
      " [ 0.61290323]\n",
      " [ 0.70967742]\n",
      " [ 0.69354839]\n",
      " [ 0.77419355]\n",
      " [ 0.16129032]\n",
      " [ 0.01612903]\n",
      " [ 0.5       ]\n",
      " [ 0.87096774]\n",
      " [ 0.01612903]\n",
      " [ 0.51612903]\n",
      " [ 0.59677419]\n",
      " [ 0.48387097]\n",
      " [ 0.75806452]\n",
      " [ 0.66129032]\n",
      " [ 0.5483871 ]\n",
      " [ 0.77419355]\n",
      " [ 0.01612903]\n",
      " [ 0.53225806]\n",
      " [ 0.61290323]\n",
      " [ 0.51612903]\n",
      " [ 0.64516129]\n",
      " [ 0.5483871 ]\n",
      " [ 0.69354839]\n",
      " [ 0.77419355]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.79032258]\n",
      " [ 0.59677419]\n",
      " [ 0.61290323]\n",
      " [ 0.77419355]\n",
      " [ 0.01612903]\n",
      " [ 0.5483871 ]\n",
      " [ 0.5       ]\n",
      " [ 0.70967742]\n",
      " [ 0.70967742]\n",
      " [ 0.64516129]\n",
      " [ 0.01612903]\n",
      " [ 0.61290323]\n",
      " [ 0.77419355]\n",
      " [ 0.01612903]\n",
      " [ 0.56451613]\n",
      " [ 0.70967742]\n",
      " [ 0.75806452]\n",
      " [ 0.01612903]\n",
      " [ 0.79032258]\n",
      " [ 0.59677419]\n",
      " [ 0.5483871 ]\n",
      " [ 0.01612903]\n",
      " [ 0.80645161]\n",
      " [ 0.77419355]\n",
      " [ 0.5483871 ]\n",
      " [ 0.01612903]\n",
      " [ 0.70967742]\n",
      " [ 0.56451613]\n",
      " [ 0.01612903]\n",
      " [ 0.48387097]\n",
      " [ 0.69354839]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(x)\n",
    "n_vocab = len(chars)\n",
    "\n",
    "x = numpy.reshape(x, [n_patterns, seq_length, 1])\n",
    "x = x / n_vocab\n",
    "\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "print(x[2])\n",
    "print(y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = (x.shape[1], x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation = \"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangxiaojun/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 116576/1013349 [==>...........................] - ETA: 51:54 - loss: 2.9552"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_next(input_array):\n",
    "    x = numpy.reshape(input_array, [1, seq_length, 1])\n",
    "    x = x / float(n_vocab)\n",
    "    y = model.predict(x)\n",
    "    return y\n",
    "\n",
    "def string_to_index(raw_input):\n",
    "    res = []\n",
    "    for c in raw_input[(len(raw_input) - seq_length) : ]:\n",
    "        res.append(char_to_int[c])\n",
    "    return res\n",
    "\n",
    "def y_to_char:\n",
    "    largest_index = y.argmax()\n",
    "    c = int_to_char[largest_index]\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_article(init, rounds=500):\n",
    "    in_string = init.lower()\n",
    "    for i in range(rounds):\n",
    "        n = y_to_char(predict_next(string_to_index(in_string)))\n",
    "        in_string += n\n",
    "    return in_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = 'Professor Michael S. Hart is the originator of the Project'\n",
    "article = generate_article(init)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
